{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8b7f259",
   "metadata": {},
   "source": [
    "# import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82f40f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "from konlpy.tag import Komoran\n",
    "\n",
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf8aa55",
   "metadata": {},
   "source": [
    "# get combined_crawling_data by mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9894aa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combined_crawling_data():\n",
    "    conn = pymysql.connect(\n",
    "        host = 'localhost',\n",
    "        port = 33060,\n",
    "        user = 'data',\n",
    "        password = 'data',\n",
    "        database = 'recommend_system',\n",
    "        charset='utf8mb4'\n",
    "    )\n",
    "    \n",
    "    ccd_query = \"SELECT * FROM combined_crawling_data\"\n",
    "    \n",
    "    ccd_df = pd.read_sql(ccd_query, conn)\n",
    "    \n",
    "    conn.close()\n",
    "\n",
    "    return ccd_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7c27f0",
   "metadata": {},
   "source": [
    "# skills 추출 후 중복 제거하고 skills_set list 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68813186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_skills_set():\n",
    "    skills_list = []\n",
    "    skills_filter = []\n",
    "\n",
    "    with open(\"data/combined_crawling_data.csv\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.reader(f)\n",
    "\n",
    "        for row in reader:\n",
    "            # row 리스트의 10번째 값을 가져와 string 을 '' 안의 단어들로 나눠서 리스트로 만들기\n",
    "            skills = re.findall(r\"'(.*?)'\", row[10])\n",
    "            skills_upper = [word.upper() for word in skills]\n",
    "\n",
    "            # 나누어진 리스트를 추가\n",
    "            skills_list += skills_upper\n",
    "\n",
    "        skillset = set(skills_list)\n",
    "\n",
    "    return skillset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c91333d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "659\n"
     ]
    }
   ],
   "source": [
    "skills_set = get_skills_set()\n",
    "print(len(skills_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b937eb17",
   "metadata": {},
   "source": [
    "## db 에서 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8f1343de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_skills_set():\n",
    "    skills_list = []\n",
    "    skills_filter = []\n",
    "    \n",
    "    ccd_df = get_combined_crawling_data()\n",
    "    \n",
    "    ccd_skills_list = ccd_df['skills'].tolist()\n",
    "    \n",
    "    for row in ccd_skills_list:\n",
    "        # row 리스트의 10번째 값을 가져와 string 을 '' 안의 단어들로 나눠서 리스트로 만들기\n",
    "        skills = re.findall(r\"'(.*?)'\", row)\n",
    "        skills_upper = [word.upper() for word in skills]\n",
    "\n",
    "        # 나누어진 리스트를 추가\n",
    "        skills_list += skills_upper\n",
    "\n",
    "    skills_set = set(skills_list)\n",
    "\n",
    "    return skills_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d5f428a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vf/p_2t8d9s3dgc1k68_4bwc6r80000gn/T/ipykernel_17663/2245305523.py:13: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  ccd_df = pd.read_sql(ccd_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "659\n"
     ]
    }
   ],
   "source": [
    "skills_set = get_skills_set()\n",
    "print(len(skills_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405498e2",
   "metadata": {},
   "source": [
    "# 리스트를 딕셔너리로 변환 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d1fd5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_dict(lst):\n",
    "    toDict = dict()\n",
    "\n",
    "    for item in lst:\n",
    "        toDict[item.upper()] = 0\n",
    "\n",
    "    return toDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63a05b6",
   "metadata": {},
   "source": [
    "# 딕셔너리를 CSV 파일로 저장하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aef48a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv_file(dict, title):\n",
    "    with open(title, \"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        writer.writerow([\"Key\", \"Kalue\"])\n",
    "        \n",
    "        for k, v in dict.items():\n",
    "            writer.writerow([k, v])\n",
    "            \n",
    "    print(\"Dictionary keys and values saved to CSV file successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc75ca5a",
   "metadata": {},
   "source": [
    "# 각 채용 링크의 qualification 속 skills_set 정리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2adc9093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qualification_skill_list():\n",
    "    com_set = get_skills_set()\n",
    "    com_list = list(com_set)\n",
    "    com_dict = list_to_dict(com_list)\n",
    "    \n",
    "    skill_dict = com_dict.copy()\n",
    "    freq_dict = dict()\n",
    "    \n",
    "    with open(\"data/combined_crawling_data.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        data = list(reader)\n",
    "        count = 1\n",
    "        \n",
    "        for row in tqdm(data[1:]):\n",
    "            id = row[0]\n",
    "            \n",
    "            # qualifications = 7, preferred = 8, skills = 10\n",
    "            quali_data = row[7].upper()\n",
    "            \n",
    "            # 확인해야하는 qualification data\n",
    "            phrases = com_list\n",
    "            \n",
    "            # remove symbols\n",
    "            sentence = re.sub(r'[^\\w\\s]', '', quali_data)\n",
    "            \n",
    "            # re.escape 로 특수문자를 벗어나고, | 로 단어 연결\n",
    "            pattern = r'\\b(' + '|'.join(map(re.escape, phrases)) + r')\\b'\n",
    "            \n",
    "            # 한글 정렬 후 나누기\n",
    "            komoran = Komoran()\n",
    "            sentence = komoran.morphs(sentence)\n",
    "            \n",
    "            # 한글 정렬 후 나누고 다시 문장으로 합쳐주기\n",
    "            sentence = \" \".join(sentence)\n",
    "            \n",
    "            # phrases 에 있는 단어를 가져와서 sentence 속 빈도 확인하기\n",
    "            matches = re.findall(pattern, sentence)\n",
    "            \n",
    "            if count % 500 == 0:\n",
    "                print(matches)\n",
    "            count += 1\n",
    "            \n",
    "            freq_dict[id] = list(set(matches))\n",
    "            \n",
    "    save_csv_file(freq_dict, \"data/freq_qual_data.csv\")\n",
    "    return freq_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699c69f2",
   "metadata": {},
   "source": [
    "## db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f91a6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qualification_skill_list():\n",
    "    com_set = get_skills_set()\n",
    "    com_list = list(com_set)\n",
    "    com_dict = list_to_dict(com_list)\n",
    "    \n",
    "    skill_dict = com_dict.copy()\n",
    "    freq_dict = dict()\n",
    "    \n",
    "    with open(\"data/combined_crawling_data.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        data = list(reader)\n",
    "        count = 1\n",
    "        \n",
    "        for row in tqdm(data[1:]):\n",
    "            id = row[0]\n",
    "            \n",
    "            # qualifications = 7, preferred = 8, skills = 10\n",
    "            quali_data = row[7].upper()\n",
    "            \n",
    "            # 확인해야하는 qualification data\n",
    "            phrases = com_list\n",
    "            \n",
    "            # remove symbols\n",
    "            sentence = re.sub(r'[^\\w\\s]', '', quali_data)\n",
    "            \n",
    "            # re.escape 로 특수문자를 벗어나고, | 로 단어 연결\n",
    "            pattern = r'\\b(' + '|'.join(map(re.escape, phrases)) + r')\\b'\n",
    "            \n",
    "            # 한글 정렬 후 나누기\n",
    "            komoran = Komoran()\n",
    "            sentence = komoran.morphs(sentence)\n",
    "            \n",
    "            # 한글 정렬 후 나누고 다시 문장으로 합쳐주기\n",
    "            sentence = \" \".join(sentence)\n",
    "            \n",
    "            # phrases 에 있는 단어를 가져와서 sentence 속 빈도 확인하기\n",
    "            matches = re.findall(pattern, sentence)\n",
    "            \n",
    "            if count % 500 == 0:\n",
    "                print(matches)\n",
    "            count += 1\n",
    "            \n",
    "            freq_dict[id] = list(set(matches))\n",
    "            \n",
    "    save_csv_file(freq_dict, \"data/freq_qual_data.csv\")\n",
    "    return freq_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e53551e",
   "metadata": {},
   "source": [
    "# 각 채용 링크의 preferred 속 skills_set 정리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b2e8987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preferred_skill_list():\n",
    "    com_set = get_skills_set()\n",
    "    com_list = list(com_set)\n",
    "    com_dict = list_to_dict(com_list)\n",
    "    \n",
    "    skill_dict = com_dict.copy()\n",
    "    freq_dict = dict()\n",
    "    \n",
    "    with open(\"data/combined_crawling_data.csv\", 'r', encoding=\"utf-8\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        data = list(reader)\n",
    "        count = 1\n",
    "        \n",
    "        for row in tqdm(data[1:]):\n",
    "            id = row[0]\n",
    "            \n",
    "            # qualifications = 7, preferred = 8, skills = 10\n",
    "            data = row[8].upper()\n",
    "\n",
    "            # 확인해야 하는 데이터 (list)\n",
    "            phrases = com_list \n",
    "\n",
    "            # remove symbols\n",
    "            sentence = re.sub(r'[^\\w\\s]', '', data)\n",
    "\n",
    "            # re.escape으로 특수문자 벗어나고, |로 단어 연결\n",
    "            pattern = r'\\b(' + '|'.join(map(re.escape, phrases)) + r')\\b'\n",
    "\n",
    "            # 한글 정렬후 나누기\n",
    "            komoran = Komoran()\n",
    "            sentence = komoran.morphs(sentence)\n",
    "\n",
    "            # 한글 정렬 후 나누고 다시 문장으로 합쳐주기\n",
    "            sentence = \" \".join(sentence)\n",
    "            \n",
    "            # phrases에 있는 단어 sentence속 빈도 확인하기\n",
    "            matches = re.findall(pattern, sentence)\n",
    "            \n",
    "\n",
    "            if count % 500 == 0:\n",
    "                print(matches)\n",
    "            count += 1\n",
    "\n",
    "            # dictionary에 하나씩 넣어주기 - set으로 중복 제거\n",
    "            freq_dict[id] = list(set(matches))\n",
    "\n",
    "    save_csv_file(freq_dict, \"data/freq_pref_data.csv\")\n",
    "    return freq_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1f5e55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                                                        | 51/5451 [01:07<1:58:18,  1.31s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_preferred_skill_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 30\u001b[0m, in \u001b[0;36mget_preferred_skill_list\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb(\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(re\u001b[38;5;241m.\u001b[39mescape, phrases)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# 한글 정렬후 나누기\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m komoran \u001b[38;5;241m=\u001b[39m \u001b[43mKomoran\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m sentence \u001b[38;5;241m=\u001b[39m komoran\u001b[38;5;241m.\u001b[39mmorphs(sentence)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# 한글 정렬 후 나누고 다시 문장으로 합쳐주기\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/konlpy/tag/_komoran.py:69\u001b[0m, in \u001b[0;36mKomoran.__init__\u001b[0;34m(self, jvmpath, userdic, modelpath, max_heap_size)\u001b[0m\n\u001b[1;32m     66\u001b[0m komoranJavaPackage \u001b[38;5;241m=\u001b[39m jpype\u001b[38;5;241m.\u001b[39mJPackage(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkr.co.shineware.nlp.komoran.core\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjki \u001b[38;5;241m=\u001b[39m \u001b[43mkomoranJavaPackage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mKomoran\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodelpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# Package kr.lucypark.komoran.KomoranInterface is not Callable\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot access komoran-dic. Please leave an issue at https://github.com/konlpy/konlpy/issues\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "get_preferred_skill_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b26fe4",
   "metadata": {},
   "source": [
    "# 각 채용 링크의 skills 속 skills_set 정리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98184832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_skills_skill_list():\n",
    "    freq_dict = dict()\n",
    "\n",
    "    with open(\"data/combined_crawling_data.csv\", 'r', encoding=\"utf-8\") as f:\n",
    "        skill_reader = csv.reader(f)\n",
    "        skill = list(skill_reader)\n",
    "\n",
    "        for row in skill[1:]:\n",
    "            id = row[0]\n",
    "            \n",
    "            data = row[10].upper()\n",
    "            \n",
    "            # id = 0,  skills = 10\n",
    "            freq_dict[id] = data\n",
    "\n",
    "    print(len(freq_dict))\n",
    "\n",
    "    save_csv_file(freq_dict, \"data/freq_skill_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9119ccb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5450\n",
      "Dictionary keys and values saved to CSV file successfully.\n"
     ]
    }
   ],
   "source": [
    "get_skills_skill_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e434314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_skills_include_skill_list():\n",
    "    freq_dict = dict()\n",
    "\n",
    "    with open(\"data/combined_crawling_data.csv\", 'r', encoding=\"utf-8\") as f:\n",
    "        skill_reader = csv.reader(f)\n",
    "        skill = list(skill_reader)\n",
    "\n",
    "        for row in skill[1:]:\n",
    "            id = row[0]\n",
    "            \n",
    "            data = row[10].upper()\n",
    "            \n",
    "            # id = 0,  skills = 10\n",
    "            freq_dict[id] = data\n",
    "\n",
    "    print(len(freq_dict))\n",
    "\n",
    "    save_csv_file(freq_dict, \"data/freq_skill_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb22454",
   "metadata": {},
   "source": [
    "# 각 리스트에 데이터를 넣어서 리스트 = 컬럼으로 한 csv 파일 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ea814aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5451 5451 5451\n",
      "135926 135926 135926\n",
      " ['SQL', '관리'] ['개발', 'ORACLE', 'JAVA', 'MSSQL', 'MYSQL', 'TOMCAT']\n",
      "149822 149822 149822\n",
      " ['개발', 'API', '서버', '설계', 'ELASTICSEARCH', 'SOLR', '검색 엔진'] ['개발', 'KUBERNETES']\n",
      "80377 80377 80377\n",
      " ['QT', 'C'] ['개발', 'VISUAL STUDIO', 'C']\n",
      "152260 152260 152260\n",
      "['GIT', 'GITLAB', 'JAVASCRIPT', 'TYPESCRIPT', 'REACT NATIVE', 'REDUX', 'NEXT.JS'] ['개발', 'API', 'TYPESCRIPT', 'REACT NATIVE', 'REST', 'CSS'] ['개발', 'IOS', 'FLOW', 'RESTFUL API', 'GIT', '리팩토링', 'ANDROID', 'REACT']\n",
      "145706 145706 145706\n",
      "['MYSQL', 'JAVA', 'KOTLIN', 'JUNIT', 'JPA', 'SPRING BOOT'] ['개발', 'SPRING BOOT', 'KOTLIN', 'ORM', 'GIT', 'JAVA', 'JPA', 'API 개발', 'MSSQL', 'RDBMS', 'MVC', '모델링', '관리'] ['개발', 'DOCKER', '설계', '검증', '최적화', 'NOSQL', 'MYSQL', 'JIRA', 'JUNIT', 'API', '서버', 'MVC', 'SPRING FRAMEWORK', 'SLACK', 'AWS', 'GRADLE', 'CONFLUENCE', 'GIT', 'JAVA', 'JPA', 'GITLAB', 'REDIS', 'JENKINS']\n",
      "163231 163231 163231\n",
      "['CISSP', 'CISA'] ['개발', '정보 보안', '보안', '네트워크 보안', '인프라', '보안 운영', '관리'] ['개발', '정보 보안', '보안', 'CISSP', '인프라', 'CISA', '관리']\n",
      "156485 156485 156485\n",
      "['JAVASCRIPT', 'PYTHON'] ['개발', 'JAVASCRIPT', 'PYTHON'] ['개발', '데이터 분석']\n",
      "154802 154802 154802\n",
      "['PYTHON', '보안', '인프라', 'AWS'] ['개발', 'JAVA', 'SPRING BOOT', 'RESTFUL API'] ['설계', 'AWS', '개발']\n",
      "162464 162464 162464\n",
      "['ANDROID', 'JAVASCRIPT', 'TYPESCRIPT', 'REACT.JS', 'REDUX', 'NEXT.JS'] ['개발'] ['개발', 'API', 'GIT', 'JAVA', 'MSSQL', 'MYSQL', 'SPRING FRAMEWORK']\n",
      "164842 164842 164842\n",
      "['GIT', 'GITHUB', 'MONGODB', 'MYSQL', 'PYTORCH', 'SCIKIT-LEARN', 'JAVASCRIPT', 'NODE.JS', 'R', 'SQL', 'AWS', 'JENKINS', 'NOSQL', 'APACHE', 'DOCKER', 'JUNIT', 'MSSQL', 'KUBERNETES'] ['개발'] ['개발', '3D', 'WEBGL']\n"
     ]
    }
   ],
   "source": [
    "total_dict = dict()\n",
    "\n",
    "ids = []\n",
    "\n",
    "with open(\"data/freq_skill_data.csv\",\"r\",encoding=\"utf-8\") as skill:\n",
    "    skill_reader = csv.reader(skill)\n",
    "    skill_rows = list(skill_reader)\n",
    "    skills = []\n",
    "\n",
    "with open(\"data/freq_qual_data.csv\",\"r\",encoding=\"cp949\") as qual:\n",
    "    qual_reader = csv.reader(qual)\n",
    "    qual_rows = list(qual_reader)\n",
    "    quals = []\n",
    "\n",
    "with open(\"data/freq_pref_data.csv\",\"r\",encoding=\"cp949\") as pref:\n",
    "    pref_reader = csv.reader(pref)\n",
    "    pref_rows = list(pref_reader)\n",
    "    prefs = []\n",
    "\n",
    "    print(len(skill_rows), len(qual_rows), len(pref_rows))\n",
    "    count = 0\n",
    "    for row in range(1, len(skill_rows)):\n",
    "        if (skill_rows[row][0] == qual_rows[row][0] == pref_rows[row][0]):\n",
    "            id = skill_rows[row][0]\n",
    "            skill = skill_rows[row][1]\n",
    "            qual = qual_rows[row][1]\n",
    "            pref = pref_rows[row][1]\n",
    "\n",
    "            # 각 리스트에도 넣어준다.\n",
    "            ids.append(id)\n",
    "            skills.append(skill)\n",
    "            quals.append(qual)\n",
    "            prefs.append(pref)\n",
    "\n",
    "        if row % 500 == 0:\n",
    "            print(skill_rows[row][0], qual_rows[row][0], pref_rows[row][0])\n",
    "            print(skill_rows[row][1], qual_rows[row][1], pref_rows[row][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10205d67",
   "metadata": {},
   "source": [
    "# quali, pref, skills 데이터 하나로 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83b4fc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataFrame\n",
    "df = pd.DataFrame({'id': ids, 'qualification': quals, 'preferred': prefs, 'skills': skills})\n",
    "\n",
    "# Save the DataFrame as a CSV file with column names\n",
    "df.to_csv('data/qual_pref_skill_combined.csv', index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1b0927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
