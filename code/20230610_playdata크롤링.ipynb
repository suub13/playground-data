{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 직무별 공고 링크 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_csvfile(title, link):\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    driver.get(link)\n",
    "    time.sleep(1)\n",
    "\n",
    "    list_container = driver.find_element(By.CLASS_NAME, 'List_List_container__JnQMS')\n",
    "\n",
    "    while True:\n",
    "        prev_li_count = len(list_container.find_elements(By.TAG_NAME, 'li'))\n",
    "        \n",
    "        html = driver.find_element(By.TAG_NAME, 'html')\n",
    "        html.send_keys(Keys.END)\n",
    "        time.sleep(2)\n",
    "\n",
    "        html1 = driver.find_element(By.TAG_NAME, 'html')\n",
    "        html1.send_keys(Keys.END)\n",
    "        time.sleep(2)\n",
    "\n",
    "        html = driver.find_element(By.TAG_NAME, 'html')\n",
    "        html.send_keys(Keys.END)\n",
    "        time.sleep(2)\n",
    "\n",
    "        html = driver.find_element(By.TAG_NAME, 'html')\n",
    "        html.send_keys(Keys.END)\n",
    "        time.sleep(2)\n",
    "\n",
    "        html = driver.find_element(By.TAG_NAME, 'html')\n",
    "        html.send_keys(Keys.END)\n",
    "        time.sleep(2)\n",
    "\n",
    "        html = driver.find_element(By.TAG_NAME, 'html')\n",
    "        html.send_keys(Keys.END)\n",
    "        time.sleep(2)\n",
    "\n",
    "        html = driver.find_element(By.TAG_NAME, 'html')\n",
    "        html.send_keys(Keys.END)\n",
    "        time.sleep(2)\n",
    "\n",
    "        current_li_count = len(list_container.find_elements(By.TAG_NAME, 'li'))\n",
    "\n",
    "        if current_li_count == prev_li_count:\n",
    "            time.sleep(10)\n",
    "            reset_count = len(list_container.find_elements(By.TAG_NAME, 'li'))\n",
    "            print(\"break \" + str(reset_count))\n",
    "            if reset_count == prev_li_count:\n",
    "                break\n",
    "\n",
    "    list_items = list_container.find_elements(By.TAG_NAME, 'li')\n",
    "\n",
    "    print(\"total amount is \" + str(len(list_items)))\n",
    "    \n",
    "    data = []\n",
    "    if os.path.isfile('job_link.csv'):\n",
    "        with open('job_link.csv', 'r', newline='') as file:\n",
    "            reader = csv.reader(file)\n",
    "            data = list(reader)\n",
    "        \n",
    "    # csv_name = title + \".csv\"\n",
    "    with open('job_link.csv', mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for item in list_items:\n",
    "            card = item.find_element(By.CLASS_NAME, 'Card_className__u5rsb')\n",
    "            anchor = card.find_element(By.TAG_NAME, 'a')\n",
    "            link = anchor.get_attribute('href')\n",
    "            data[1:] += [(title, link)]\n",
    "            # writer.writerow([title, link])\n",
    "        writer.writerows(data)\n",
    "    \n",
    "\n",
    "    # driver.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"job_category.csv\", 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        job_title = row[0]\n",
    "        job_link = row[1]\n",
    "        print(job_title)\n",
    "        category_csvfile(job_title, job_link)\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 웹사이트 직무별 공고 리스트 중복 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 직무별 numbering 딕셔너리 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "job_dict = dict()\n",
    "count = 0\n",
    "with open(\"job_category.csv\",'r',newline='') as jobcategoryfile:\n",
    "    reader = csv.reader(jobcategoryfile)\n",
    "    for job in reader:\n",
    "        job_dict[job[0]] = count\n",
    "        count += 1\n",
    "\n",
    "print(job_dict)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 직무 별 link 중복 확인 후, 링크별로 정리"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 해당 링크에 중복되는 직무 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getJobs(link):\n",
    "    with open(\"job_link.csv\",'r', newline='') as joblistfile:\n",
    "        jobs = []\n",
    "        reader = csv.reader(joblistfile)\n",
    "        for i in reader:\n",
    "            if link == i[1]:\n",
    "                jobs.append(i[0])\n",
    "        return jobs\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 링크를 중복없이 set로 묶고 링크 직무찾는 함수 호출 후, 링크 + 해당 직무 줄 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findJobsForLink(file):\n",
    "    total = 0\n",
    "    with open(file,'r', newline='') as joblistfile:\n",
    "        reader = csv.reader(joblistfile)\n",
    "        data = list(reader)\n",
    "        link_list = [lst[1] for lst in data]\n",
    "\n",
    "        link_set = set(link_list)\n",
    "        print(len(link_set))\n",
    "        with open(\"id_link_job.csv\",\"w\",newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"id\",\"url\",\"jobs\"])\n",
    "            for link in link_set:\n",
    "                jobs = getJobs(link)\n",
    "                total += len(jobs)\n",
    "                writer.writerow([link.split(\"/\")[-1],link, jobs])\n",
    "    return total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5462\n",
      "11758\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "print(findJobsForLink(\"job_link.csv\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 직무 별 link 중복 확인 후, 링크별로 정리"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 링크 row 당 직무 column 만들기 위해 dictionary 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'웹 개발자': 0, '서버 개발자': 0, '소프트웨어 엔지니어': 0, '프론트엔드 개발자': 0, '자바 개발자': 0, 'C, C++ 개발자': 0, '안드로이드 개발자': 0, '파이썬 개발자': 0, 'Node.js 개발자': 0, 'iOS 개발자': 0, '머신러닝 엔지니어': 0, '데이터 엔지니어': 0, '시스템, 네트워크 관리자': 0, 'DevOps/ 시스템 관리자': 0, '개발 매니저': 0, '기술지원': 0, 'QA,테스트 엔지니어': 0, '데이터 사이언티스트': 0, '임베디드 개발자': 0, '보안 엔지니어': 0, '프로덕트 매니저': 0, '빅데이터 엔지니어': 0, '하드웨어 엔지니어': 0, 'PHP 개발자': 0, '블록체인 플랫폼 엔지니어': 0, '크로스플랫폼 앱 개발자': 0, 'DBA': 0, 'ERP전문가': 0, '.NET 개발자': 0, '웹 퍼블리셔': 0, '영상,음성 엔지니어': 0, '그래픽스 엔지니어': 0, '루비온레일즈 개발자': 0, 'BI 엔지니어': 0, 'VR 엔지니어': 0}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "job_dict = dict()\n",
    "with open(\"../data/job_category.csv\",'r',newline='') as jobcategoryfile:\n",
    "    reader = csv.reader(jobcategoryfile)\n",
    "    for job in reader:\n",
    "        job_dict[job[0]] = 0\n",
    "print(job_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 해당 링크에 중복되는 직무 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getJobs(link):\n",
    "    with open(\"job_link.csv\",'r', newline='') as joblistfile:\n",
    "        jobs = []\n",
    "        reader = csv.reader(joblistfile)\n",
    "        for i in reader:\n",
    "            if link == i[1]:\n",
    "                jobs.append(i[0])\n",
    "        return jobs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 링크를 중복없이 set로 묶고 링크 직무찾는 함수 호출 후, 링크 + 해당 직무 줄 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5462\n",
      "11758\n"
     ]
    }
   ],
   "source": [
    "def findJobsForLinkPivot(file):\n",
    "    total = 0\n",
    "    with open(file,'r', newline='') as joblistfile:\n",
    "        reader = csv.reader(joblistfile)\n",
    "        data = list(reader)\n",
    "\n",
    "        # 링크를 중복없이 set로 묶기\n",
    "        link_list = [lst[1] for lst in data]\n",
    "        link_set = set(link_list)\n",
    "\n",
    "        # 링크 unique value 개수 확인\n",
    "        print(len(link_set))\n",
    "\n",
    "        # 해당 링크 값 갖고 있는 직무 확인하기 \n",
    "        with open(\"id_link_job_pivot.csv\",\"w\",newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"id\",\"url\"] +list(job_dict.keys()))\n",
    "            for link in link_set:\n",
    "                job_cols = job_dict.copy()\n",
    "                jobs = getJobs(link)\n",
    "                for job in jobs:\n",
    "                    job_cols[job] = 1\n",
    "                total += len(jobs)\n",
    "                writer.writerow([link.split(\"/\")[-1], link] + list(job_cols.values()))\n",
    "    return total\n",
    "\n",
    "import csv\n",
    "print(findJobsForLinkPivot(\"job_link.csv\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot 형식이 아닌 id, url, [jobs] 형식"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 중복직무확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getJobs(link):\n",
    "    with open(\"job_link.csv\",'r', newline='') as joblistfile:\n",
    "        jobs = []\n",
    "        reader = csv.reader(joblistfile)\n",
    "        for i in reader:\n",
    "            if link == i[1]:\n",
    "                jobs.append(i[0])\n",
    "        return jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findJobsForLink(file):\n",
    "    total = 0\n",
    "    with open(file,'r', newline='') as joblistfile:\n",
    "        reader = csv.reader(joblistfile)\n",
    "        data = list(reader)\n",
    "\n",
    "        # 링크를 중복없이 set로 묶기\n",
    "        link_list = [lst[1] for lst in data]\n",
    "        link_set = set(link_list)\n",
    "\n",
    "        # 링크 unique value 개수 확인\n",
    "        print(len(link_set))\n",
    "\n",
    "        # 해당 링크 값 갖고 있는 직무 확인하기 \n",
    "        with open(\"id_link_job_pivot.csv\",\"w\",newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"id\",\"url\"] +list(job_dict.keys()))\n",
    "            for link in link_set:\n",
    "                job_cols = job_dict.copy()\n",
    "                jobs = getJobs(link)\n",
    "                for job in jobs:\n",
    "                    job_cols[job] = 1\n",
    "                total += len(jobs)\n",
    "                writer.writerow([link.split(\"/\")[-1], link] + list(job_cols.values()))\n",
    "    return total\n",
    "\n",
    "import csv\n",
    "print(findJobsForLink(\"job_link.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
